{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0044499649\n",
      "19.9437542888\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.tools.numdiff as smnd\n",
    "import numpy as np\n",
    "import numba\n",
    "import random\n",
    "import math\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "random.seed()\n",
    "\n",
    "def mh_step(x, log_post, log_post_current, sigma, args=()):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray, shape (n_variables,)\n",
    "        The present location of the walker in parameter space.\n",
    "    log_post : function\n",
    "        The function to compute the log posterior. It has call\n",
    "        signature `log_post(x, *args)`.\n",
    "    log_post_current : float\n",
    "        The current value of the log posterior.\n",
    "    sigma : ndarray, shape (n_variables, )\n",
    "        The standard deviations for the proposal distribution.\n",
    "    args : tuple\n",
    "        Additional arguments passed to `log_post()` function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_out : ndarray, shape (n_variables,)\n",
    "        The position of the walker after the Metropolis-Hastings\n",
    "        step. If no step is taken, returns the inputted `x`.\n",
    "    log_post_updated : float\n",
    "        The log posterior after the step.\n",
    "    accepted : bool\n",
    "        True is the proposal step was taken, False otherwise.\n",
    "    \"\"\"\n",
    "    mu, inv_cov = args\n",
    "    \n",
    "    #Sample next point\n",
    "    nextPoint = np.random.multivariate_normal(x, cov)\n",
    "\n",
    "    #Calculate metropolis ratio\n",
    "    logmetropolisRatio = log_post(nextPoint, *args) - log_post_current\n",
    "    \n",
    "    #This is converting the log metropolis ratio to an actual value between 0 and 1 for probability\n",
    "    logMetropolisRatioEx = np.exp(log_post(nextPoint, *args))/ np.exp(log_post_current)\n",
    "    \n",
    "    #Random decimal between 0 and 1 to decide if we should proceed with new point at a certain probability\n",
    "    n = random.uniform(0,1)\n",
    "    \n",
    "    #If metropolis ratio is >= 1 or the random n is less than the probability (meaning we proceed with the new point)\n",
    "    #at a probability of logMetropolisRatioEx\n",
    "    if (logmetropolisRatio >= 1 or n <= logMetropolisRatioEx):\n",
    "        return nextPoint, log_post(np.array(nextPoint), *args), True\n",
    "    else:\n",
    "        return x, log_post_current, False\n",
    "    \n",
    "def mh_sample(log_post, x0, sigma, args=(), n_burn=1000, n_steps=5000,\n",
    "              variable_names=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_post : function\n",
    "        The function to compute the log posterior. It has call\n",
    "        signature `log_post(x, *args)`.\n",
    "    x0 : ndarray, shape (n_variables,)\n",
    "        The starting location of a walker in parameter space.\n",
    "    sigma : ndarray, shape (n_variables, )\n",
    "        The standard deviations for the proposal distribution.\n",
    "    args : tuple\n",
    "        Additional arguments passed to `log_post()` function.\n",
    "    n_burn : int, default 1000\n",
    "        Number of burn-in steps.\n",
    "    n_steps : int, default 1000\n",
    "        Number of steps to take after burn-in.\n",
    "    variable_names : list, length n_variables\n",
    "        List of names of variables. If None, then variable names\n",
    "        are sequential integers.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output : DataFrame\n",
    "        The first `n_variables` columns contain the samples.\n",
    "        Additionally, column 'lnprob' has the log posterior value\n",
    "        at each sample.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    lnprob = []\n",
    "    finalPoint = x0\n",
    "    new_mu, new_cov = args\n",
    "    logPostCurrent = log_post(x0, *args)\n",
    "    isAccepted = True\n",
    "    \n",
    "    #Burn-in period\n",
    "    \n",
    "    for i in range(n_burn):\n",
    "        finalPoint, logPostCurrent, isAccepted = mh_step(finalPoint, log_post, logPostCurrent, sigma, args)\n",
    "    \n",
    "    #After burn-in, we actually log in sample and log posterior values\n",
    "    for j in range(n_steps):\n",
    "        finalPoint, logPostCurrent, isAccepted = mh_step(finalPoint, log_post, logPostCurrent, sigma, args)\n",
    "        samples.append(finalPoint)\n",
    "        lnprob.append(logPostCurrent)\n",
    "    d = {'Samples': samples, 'Log Posterior Value': lnprob}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df\n",
    "        \n",
    "mu = np.array([10.0, 20])\n",
    "cov = np.array([[4, -2],[-2, 6]])\n",
    "inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def log_test_distribution(x, mu, inv_cov):\n",
    "    \"\"\"\n",
    "    Unnormalized log posterior of a multivariate Gaussian.\n",
    "    \"\"\"\n",
    "    return -np.dot((x-mu), np.dot(inv_cov, (x-mu))) / 2\n",
    "def log_test_distribution(x, mu, inv_cov):\n",
    "    \"\"\"\n",
    "    Unnormalized log posterior of a multivariate Gaussian.\n",
    "    \"\"\"\n",
    "    return -np.dot((x-mu), np.dot(inv_cov, (x-mu))) / 2\n",
    "\n",
    "#Initial guess: X0\n",
    "x0 = np.array([5.0, 15.0])\n",
    "_out = mh_sample(log_test_distribution,x0 , cov, args=(mu, inv_cov))\n",
    "\n",
    "#Variables for keeping track of totals for both means so we can get average later\n",
    "totalFirst = 0\n",
    "totalSecond = 0\n",
    "count = 0\n",
    "\n",
    "\n",
    "for i in _out['Samples']:\n",
    "    totalFirst += i[0]\n",
    "    totalSecond += i[1]\n",
    "    count += 1\n",
    "    \n",
    "#Output averages\n",
    "print (totalFirst/count)\n",
    "print (totalSecond / count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
