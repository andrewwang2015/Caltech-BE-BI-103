{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) The steps to arriving at the final form of the posterior are as follows:\n",
    "\n",
    "$1$. Write a mathematical model (based on a theoretical framework) that describes the parameter we wish to estimate. \n",
    "\n",
    "$2$. Build a statistical model that describes how the measurements deviate from their theoretical value.\n",
    "\n",
    "$3$. Construct the likelihood function, incorporating both the mathematical and the statistical model.\n",
    "\n",
    "$4$. Come up with a prior function that accurately describes our estimate for the parameter. For practical applications, the distribution of the prior should be bounded, meaning we should assign upper and lower bounds on the range of possible values the prior can take. \n",
    "\n",
    "$5$. According to Bayes' Theorem, we have\n",
    "\n",
    "\\begin{align}\n",
    "Posterior = \\frac{Prior * Likelihood}{Evidence}\n",
    "\\end{align}\n",
    "\n",
    "The evidence is independent of the parameter we wish to estimate. Therefore, we can find the posterior distribution by multiplying the prior with the likelihood and normalizing the result. \n",
    "\n",
    "$6$. Once the posterior is normalized, we're done! The normalized posterior tells us everything we want to know about the parameter in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">2.5/10  \n",
    "Nice sketch. Just note - we've never used a fully normalized posterior (i.e. where we compute the evidence by fully marginalizing the likelihood and prior) in class, have we? We can find the parameter values that maximize the posterior without doing that, because the evidence is just a normalization constant.Other things you could include: common choices for likelihood (what kinds of data and parameter values are they appropriate for?), how the likelihood is a product over the probability of observing each individual data point, and how to choose priors (informative or not, normalized or not, scale v. location parameters).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b) \n",
    "\n",
    "Exercise $1$: For the likelihood, we assume that the error between the measured mean number of repressors and the theoretical mean number of receptors is Gaussian distributed. We think this assumption is justified if we assume that measurement errors come from a large number of independent random variables due to Lyapunov's Central Limit Theorem. \n",
    "\n",
    "This assumption gives us an expression for the Likelihood: \n",
    "\n",
    "\\begin{align}\n",
    "Likelihood = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\large{e^{\\frac{(x - f)^2}{2\\sigma^2}}}\n",
    "\\end{align}\n",
    "\n",
    "Here, f is the theoretical function that represents the mean number of repressors.\n",
    "\n",
    "Now, let's work on the prior: \n",
    "\n",
    "We know that a previous paper reported their estimate of the mean with error bars. This suggests that we can use a Gaussian prior for the mean number of repressors. \n",
    "\n",
    "\\begin{align}\n",
    "Prior(repressors) = \\frac{1}{\\sqrt{2\\pi(10^3)^2}}\\large{e^{\\frac{(x - 10^6)^2}{2(10^3)^2}}} = \\frac{1}{\\sqrt{2\\pi(10^6)}}\\large{e^{\\frac{(x - 10^6)^2}{2(10^6)}}}\n",
    "\\end{align}\n",
    "\n",
    "For $\\sigma$, we will use Jeffrey's prior:\n",
    "\n",
    "\\begin{align}\n",
    "Prior(\\sigma) = \\frac{1}{\\sigma\\ln{\\large{\\frac{\\sigma_{max}}{\\sigma_{min}}}}}\n",
    "\\end{align}\n",
    "\n",
    "Assume the two parameters are independent. Combining the two priors gives us a final expression for the prior: \n",
    "\n",
    "\\begin{align}\n",
    "Prior(\\sigma) = \\frac{1}{\\sqrt{2\\pi(10^6)}}\\large{e^{\\frac{(x - 10^6)^2}{2(10^6)}}}\\frac{1}{\\sigma\\ln{\\large{\\frac{\\sigma_{max}}{\\sigma_{min}}}}}\n",
    "\\end{align}\n",
    "\n",
    "x corresponds to the measured mean number of repressors. f is the theoretical function that gives the mean number of receptors. $\\sigma_{min}$ and $\\sigma_{max}$ correspond to our guesses for the minimum and maximum standard deviation in the likelihood function, respectively. $\\sigma$ is the standard deviation of the likelihood function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">4.5/5  \n",
    "\n",
    "Just note that your likelihood should be a product, and the argument of the exponent is negative:\n",
    "\n",
    "\\begin{align}\n",
    "Likelihood = \\prod_i \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\large{e^{-\\frac{(x - f_i)^2}{2\\sigma^2}}}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Also, you should out write more explicitly what $Likelihood$ is - $P(\\{f_i\\} \\mid x, \\sigma, I)$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Exercise $2$: \n",
    "\n",
    "This exercise is very similar to Exercise 1. Just as earlier, we will assume that the error between measured fluorescence and theoretical fluorescence comes from many independent subprocesses, leading to a Gaussian likelihood. \n",
    "\n",
    "The likelihood is then given by: \n",
    "\n",
    "\\begin{align}\n",
    "Likelihood = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\large{e^{\\frac{(x - f(a,b))^2}{2\\sigma^2}}}\n",
    "\\end{align}\n",
    "\n",
    "Just as earlier, we're assuming Jeffrey's prior on $\\sigma$. We don't have any prior information on $a$ and $b$, so we choose the uniform prior on both.\n",
    "\n",
    "\\begin{align}\n",
    "Prior(\\sigma) = \\frac{1}{\\sigma\\ln{\\large{\\frac{\\sigma_{max}}{\\sigma_{min}}}}}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "Prior(a) = \\frac{1}{a_{max} - a_{min}}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "Prior(b) = \\frac{1}{b_{max} - b_{min}}\n",
    "\\end{align}\n",
    "\n",
    "Assume the three parameters are independent of one another. Combining the three priors gives us a final expression for the prior:\n",
    "\n",
    "\\begin{align}\n",
    "Prior = \\frac{1}{(b_{max} - b_{min})}\\frac{1}{(a_{max} - a_{min})}\\frac{1}{\\sigma\\ln{\\large{\\frac{\\sigma_{max}}{\\sigma_{min}}}}}\n",
    "\\end{align}\n",
    "\n",
    "It's important to define each parameter or variable used in the prior and likelihood:\n",
    "\n",
    "x - measured fluorescence\n",
    "\n",
    "f(a,b) - theoretical fluorescence, given by the equation f(a,b) = $a$N + $b$. N is a known constant. \n",
    "\n",
    "$a$ and $b$ - parameters that relate the fluorescence to the number of fluorophores (see the above equation for f(a,b))\n",
    "\n",
    "$\\sigma$ - standard deviation of the likelihood function\n",
    "\n",
    "$b_{max}, b_{min}, a_{max}, a_{min}, \\sigma_{max}, \\sigma_{min}$ are our guesses for the minimum and maximum values for the three parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">4/5  \n",
    "\n",
    "Likelihood has similar errors as above. Also, be a little more precise in your definition of parameter values: $\\sigma$ is the error between the data and model prediction.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: The problem description suggests that receptors coming together is a rare event and that each occurance is independent of all the previous occurances. This is the description of a Poisson process. The waiting time for an arrival of a Poisson process is exponentially distributed. The problem asks us to estimate the average rate at which the rare events occur. Rate is in the units of inverse-time, so we can write the functional form of the likelihood for each time measurement: \n",
    "\n",
    "\\begin{align}\n",
    "Likelihood_i = re^{\\large{-rt_i}}\n",
    "\\end{align}\n",
    "\n",
    "Assuming that each measurement is independent, the combined likelihood is as follows:\n",
    "\n",
    "\\begin{align}\n",
    "Likelihood = \\prod_{i\\in D}{re^{\\large{-rt_i}}}\n",
    "\\end{align}\n",
    "\n",
    "Here, $r$ is the rate parameter we want to estimate and $t_i$ are the time measurements.\n",
    "\n",
    "Now, let's find the prior function. We see that r is a rate parameter and it's possible to replace $r$ with a different parameter corresponding to its reciprocal without altering the form of the likelihood: ($\\tau = \\large{\\frac{1}{r}}$)\n",
    "\n",
    "\\begin{align}\n",
    "Likelihood = \\prod_{i\\in D}{\\frac{1}{\\tau} e^{\\large{-\\frac{\\large{t_i}}{\\large{\\tau}}}}}\n",
    "\\end{align}\n",
    "\n",
    "When estimating rate parameters, it's appropriate to use Jeffrey's prior as an uninformative prior. Therefore, we have the following expression for the prior:\n",
    "\n",
    "\\begin{align}\n",
    "Prior = \\frac{1}{r\\ln{\\large{\\frac{r_{max}}{r_{min}}}}}\n",
    "\\end{align}\n",
    "\n",
    "where $r_{max}$ and $r_{min}$ correspond to our guesses for the maximum and minimum values of r, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">4.5/5  \n",
    "Nice! Just notice that it would help to define your prior as a piecewise function (such that it's equal to negative infinity when $r$ is outside the range $r_{min} \\leq r \\leq r_{max}$). Then the form you've written is also properly normalized.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Exercise 4: The number of arrivals in unit time is Poisson distributed for independent rare events. Assuming each measurement is independent of all the other measurements, the likelihood is:\n",
    "\n",
    "\\begin{align}\n",
    "Likelihood =  \\prod_{i\\in D}\\large{\\frac{(\\lambda t)^{x_i} e^{-\\lambda t}}{x_i!}}\n",
    "\\end{align}\n",
    "\n",
    "Here, $t$ is a constant, equal to ten minutes (the interval length). $\\lambda$ is the rate parameter we want to estimate. $x_i$ are the measurements for the number of times receptor complexes spontaneously formed. \n",
    "\n",
    "Unlike Exercise 3, our prior is informative and based on a previously written paper that gives an estimate for the mean and the error bar. We will assume that the final result reported in the paper comes from many independent measurements of the mean. If so, the functional form of the prior becomes a Gaussian with the mean and standard deviation corresponding to the mean and error stated in the paper:\n",
    "\n",
    "\\begin{align}\n",
    "Prior = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\large{e^{\\frac{(\\lambda - \\mu)^2}{2\\sigma^2}}}\n",
    "\\end{align}\n",
    "\n",
    "Here, $\\mu$ and $\\sigma$ are the reported mean and error, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">5/5  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5: The problem statement matches the story of the Gamma distribution. Any multistep process where each step happens at the same rate can be modelled with the Gamma distribution:\n",
    "\n",
    "\\begin{align}\n",
    "Likelihood =  \\prod_{i\\in D}\\large{\\frac{1}{\\Gamma(a)}\\frac{(rt_i)^a}{t_i}e^{-rt_i}}\n",
    "\\end{align}\n",
    "\n",
    "Here, $a$ denotes the number of proteins in the complex and $r$ denotes the averate rate at which each protein joins the complex. Each $t_i$ is a separate measurement of the time it takes the complex to fully form after adding the ligand.\n",
    "\n",
    "This function has two parameters, $r$ and $a$. We want to pick uninformed priors for both of them. Notice that $r$ is a rate parameter because it can be replaced with a different parameter equal to its reciprocal. However, $a$ is not a rate parameter because replacing it with its reciprocal changes the functional form of the likelihood. In light of this, we will pick Jeffrey's prior on $r$ and uniform prior on $a$: \n",
    "\n",
    "\\begin{align}\n",
    "Prior(r) = \\frac{1}{r\\ln{\\large{\\frac{r_{max}}{r_{min}}}}}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "Prior(a) = \\frac{1}{a_{max} - a_{min}}\n",
    "\\end{align}\n",
    "\n",
    "Assume $r$ and $a$ are independent. Then, the combined prior is: \n",
    "\n",
    "\\begin{align}\n",
    "Prior  = \\frac{1}{a_{max} - a_{min}}\\frac{1}{r\\ln{\\large{\\frac{r_{max}}{r_{min}}}}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert alert-info\">4.5/5 \n",
    "\n",
    "Great! Could just be slightly more detailed as to how the data matches the story.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Final: 25/25 </div>\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
