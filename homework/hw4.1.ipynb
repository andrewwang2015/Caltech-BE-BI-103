{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BE/Bi 103, Fall 2016: Homework 4\n",
    "## Due 1pm, Sunday, October 23\n",
    "\n",
    "(c) 2016 Justin Bois. With the exception of the images, this work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained therein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "*This homework was generated from an Jupyter notebook.  You can download the notebook [here](hw4.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.tools.numdiff as smnd\n",
    "import numpy as np\n",
    "import numba\n",
    "import random\n",
    "import math\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.1: Writing your own MCMC sampler (60 pts + 40 pts extra credit)\n",
    "\n",
    "**a)** Write your own MCMC sampler that employs a Metropolis-Hastings algorithm that uses a Gaussian proposal distribution. Since you are sampling multiple parameters, your proposal distribution will be multi-dimensional. You can use a Gaussian proposal distribution with a diagonal covariance. In other words, you generate a proposal for each variable in the posterior independently.\n",
    "\n",
    "You can organize your code how you like, but here is a suggestion.\n",
    "\n",
    "* Write a function that takes (or rejects) a Metropolis-Hastings step. It should look something like the below (obviously where it does something instead of `pass`ing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def mh_step(x, log_post, log_post_current, sigma, args=()):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray, shape (n_variables,)\n",
    "        The present location of the walker in parameter space.\n",
    "    log_post : function\n",
    "        The function to compute the log posterior. It has call\n",
    "        signature `log_post(x, *args)`.\n",
    "    log_post_current : float\n",
    "        The current value of the log posterior.\n",
    "    sigma : ndarray, shape (n_variables, )\n",
    "        The standard deviations for the proposal distribution.\n",
    "    args : tuple\n",
    "        Additional arguments passed to `log_post()` function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_out : ndarray, shape (n_variables,)\n",
    "        The position of the walker after the Metropolis-Hastings\n",
    "        step. If no step is taken, returns the inputted `x`.\n",
    "    log_post_updated : float\n",
    "        The log posterior after the step.\n",
    "    accepted : bool\n",
    "        True is the proposal step was taken, False otherwise.\n",
    "    \"\"\"\n",
    "    mu, inv_cov = args\n",
    "    \n",
    "    #Sample next point\n",
    "    nextPoint = np.random.multivariate_normal(x, cov)\n",
    "\n",
    "    #Calculate metropolis ratio\n",
    "    logmetropolisRatio = log_post(nextPoint, *args) - log_post_current\n",
    "    \n",
    "    #This is converting the log metropolis ratio to an actual value between 0 and 1 for probability\n",
    "    logMetropolisRatioEx = np.exp(log_post(nextPoint, *args))/ np.exp(log_post_current)\n",
    "    \n",
    "    #Random decimal between 0 and 1 to decide if we should proceed with new point at a certain probability\n",
    "    n = random.uniform(0,1)\n",
    "    \n",
    "    #If metropolis ratio is >= 1 or the random n is less than the probability (meaning we proceed with the new point)\n",
    "    #at a probability of logMetropolisRatioEx\n",
    "    if (logmetropolisRatio >= 1 or n <= logMetropolisRatioEx):\n",
    "        return nextPoint, log_post(np.array(nextPoint), *args), True\n",
    "    else:\n",
    "        return x, log_post_current, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Looks good. 20/20 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write another function that calls that function over and over again to do the sampling. It should look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mh_sample(log_post, x0, sigma, args=(), n_burn=1000, n_steps=5000,\n",
    "              variable_names=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_post : function\n",
    "        The function to compute the log posterior. It has call\n",
    "        signature `log_post(x, *args)`.\n",
    "    x0 : ndarray, shape (n_variables,)\n",
    "        The starting location of a walker in parameter space.\n",
    "    sigma : ndarray, shape (n_variables, )\n",
    "        The standard deviations for the proposal distribution.\n",
    "    args : tuple\n",
    "        Additional arguments passed to `log_post()` function.\n",
    "    n_burn : int, default 1000\n",
    "        Number of burn-in steps.\n",
    "    n_steps : int, default 1000\n",
    "        Number of steps to take after burn-in.\n",
    "    variable_names : list, length n_variables\n",
    "        List of names of variables. If None, then variable names\n",
    "        are sequential integers.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output : DataFrame\n",
    "        The first `n_variables` columns contain the samples.\n",
    "        Additionally, column 'lnprob' has the log posterior value\n",
    "        at each sample.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    lnprob = []\n",
    "    finalPoint = x0\n",
    "    new_mu, new_cov = args\n",
    "    logPostCurrent = log_post(x0, *args)\n",
    "    isAccepted = True\n",
    "    \n",
    "    #Burn-in period\n",
    "    \n",
    "    for i in range(n_burn):\n",
    "        finalPoint, logPostCurrent, isAccepted = mh_step(finalPoint, log_post, logPostCurrent, sigma, args)\n",
    "    \n",
    "    #After burn-in, we actually log in sample and log posterior values\n",
    "    for j in range(n_steps):\n",
    "        finalPoint, logPostCurrent, isAccepted = mh_step(finalPoint, log_post, logPostCurrent, sigma, args)\n",
    "        samples.append(finalPoint)\n",
    "        lnprob.append(logPostCurrent)\n",
    "    d = {'Samples': samples, 'Log Posterior Value': lnprob}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Also looks good. 20/20 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** To test your code, we will get samples out of a known distribution. We will use a bivariate Gaussian with a mean of $\\boldsymbol{\\mu} = (10, 20)$ and covariance matrix of \n",
    "\n",
    "\\begin{align}\n",
    "\\boldsymbol{\\sigma} = \\begin{pmatrix}\n",
    "4 & -2 \\\\\n",
    "-2 & 6\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "I have written the function to be unnormalized and JITted with numba for optimal speed.\n",
    "\n",
    "Do not be confused: In this test function we are sampling $\\mathbf{x}$ out of $P(\\mathbf{x}\\mid \\boldsymbol{\\mu},\\boldsymbol{\\sigma})$. This is not sampling a posterior; it's just a test for your code. You will pass `log_test_distribution` as the `log_post` argument in the above functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu = np.array([10.0, 20])\n",
    "cov = np.array([[4, -2],[-2, 6]])\n",
    "inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def log_test_distribution(x, mu, inv_cov):\n",
    "    \"\"\"\n",
    "    Unnormalized log posterior of a multivariate Gaussian.\n",
    "    \"\"\"\n",
    "    return -np.dot((x-mu), np.dot(inv_cov, (x-mu))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log Posterior Value</th>\n",
       "      <th>Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.077520</td>\n",
       "      <td>[10.7286131875, 19.3016183674]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.077520</td>\n",
       "      <td>[10.7286131875, 19.3016183674]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.077520</td>\n",
       "      <td>[10.7286131875, 19.3016183674]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.408060</td>\n",
       "      <td>[6.67185386951, 22.1487422519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.408060</td>\n",
       "      <td>[6.67185386951, 22.1487422519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.024009</td>\n",
       "      <td>[9.0356884497, 17.4692309232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.024009</td>\n",
       "      <td>[9.0356884497, 17.4692309232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.134261</td>\n",
       "      <td>[8.98804170429, 20.75605361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.134261</td>\n",
       "      <td>[8.98804170429, 20.75605361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.017121</td>\n",
       "      <td>[9.70440519007, 19.8988161759]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.017121</td>\n",
       "      <td>[9.70440519007, 19.8988161759]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.415140</td>\n",
       "      <td>[8.38208592649, 19.8712268123]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.415140</td>\n",
       "      <td>[8.38208592649, 19.8712268123]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.315686</td>\n",
       "      <td>[6.97503263407, 20.2014422706]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.315686</td>\n",
       "      <td>[6.97503263407, 20.2014422706]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.315686</td>\n",
       "      <td>[6.97503263407, 20.2014422706]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.315686</td>\n",
       "      <td>[6.97503263407, 20.2014422706]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.315686</td>\n",
       "      <td>[6.97503263407, 20.2014422706]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.070401</td>\n",
       "      <td>[7.98173360268, 18.6401116949]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.066450</td>\n",
       "      <td>[7.10899129469, 20.9795797765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.066450</td>\n",
       "      <td>[7.10899129469, 20.9795797765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.489592</td>\n",
       "      <td>[6.6686537179, 22.6773977697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.489592</td>\n",
       "      <td>[6.6686537179, 22.6773977697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-2.576313</td>\n",
       "      <td>[8.33565297296, 25.5545207379]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.997970</td>\n",
       "      <td>[9.26245316467, 24.7619198777]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.997970</td>\n",
       "      <td>[9.26245316467, 24.7619198777]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-4.716039</td>\n",
       "      <td>[13.5564235795, 23.8209134901]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-4.716039</td>\n",
       "      <td>[13.5564235795, 23.8209134901]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-4.716039</td>\n",
       "      <td>[13.5564235795, 23.8209134901]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-3.384662</td>\n",
       "      <td>[12.8841377151, 23.4003276803]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>-1.263057</td>\n",
       "      <td>[12.5713861744, 16.6249206265]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>-2.695374</td>\n",
       "      <td>[11.9650971125, 14.3135458261]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>-1.013874</td>\n",
       "      <td>[12.3137576346, 16.9865388333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>-1.013874</td>\n",
       "      <td>[12.3137576346, 16.9865388333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>-1.013874</td>\n",
       "      <td>[12.3137576346, 16.9865388333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>-1.013874</td>\n",
       "      <td>[12.3137576346, 16.9865388333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>-1.013874</td>\n",
       "      <td>[12.3137576346, 16.9865388333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>-1.013874</td>\n",
       "      <td>[12.3137576346, 16.9865388333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>-1.762624</td>\n",
       "      <td>[12.6664151423, 15.7106073749]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>-1.762624</td>\n",
       "      <td>[12.6664151423, 15.7106073749]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>-3.189668</td>\n",
       "      <td>[14.638704364, 15.4446450984]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>-3.391823</td>\n",
       "      <td>[14.8454673663, 15.4395006605]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>-4.333006</td>\n",
       "      <td>[14.7817210533, 13.7686983742]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>-1.736785</td>\n",
       "      <td>[13.1654098508, 16.2165969536]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>-1.736785</td>\n",
       "      <td>[13.1654098508, 16.2165969536]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>-1.736785</td>\n",
       "      <td>[13.1654098508, 16.2165969536]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>-1.736785</td>\n",
       "      <td>[13.1654098508, 16.2165969536]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>-2.151977</td>\n",
       "      <td>[12.3666484503, 15.0063617551]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>-1.780871</td>\n",
       "      <td>[13.6690386714, 19.1561400494]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>-0.677163</td>\n",
       "      <td>[12.2034461395, 18.0600269499]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>-0.966687</td>\n",
       "      <td>[9.45445477327, 17.2240279718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>-0.966687</td>\n",
       "      <td>[9.45445477327, 17.2240279718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>-0.966687</td>\n",
       "      <td>[9.45445477327, 17.2240279718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>-0.919091</td>\n",
       "      <td>[8.48391877896, 18.2445215839]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>-0.919091</td>\n",
       "      <td>[8.48391877896, 18.2445215839]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-0.830983</td>\n",
       "      <td>[12.3627094618, 17.6645926402]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-0.830983</td>\n",
       "      <td>[12.3627094618, 17.6645926402]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-0.499284</td>\n",
       "      <td>[10.976276846, 17.5621315409]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-0.993457</td>\n",
       "      <td>[9.54927158214, 17.1139946106]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-1.524143</td>\n",
       "      <td>[11.4809659176, 15.7240042715]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Log Posterior Value                         Samples\n",
       "0               -0.077520  [10.7286131875, 19.3016183674]\n",
       "1               -0.077520  [10.7286131875, 19.3016183674]\n",
       "2               -0.077520  [10.7286131875, 19.3016183674]\n",
       "3               -1.408060  [6.67185386951, 22.1487422519]\n",
       "4               -1.408060  [6.67185386951, 22.1487422519]\n",
       "5               -1.024009   [9.0356884497, 17.4692309232]\n",
       "6               -1.024009   [9.0356884497, 17.4692309232]\n",
       "7               -0.134261    [8.98804170429, 20.75605361]\n",
       "8               -0.134261    [8.98804170429, 20.75605361]\n",
       "9               -0.017121  [9.70440519007, 19.8988161759]\n",
       "10              -0.017121  [9.70440519007, 19.8988161759]\n",
       "11              -0.415140  [8.38208592649, 19.8712268123]\n",
       "12              -0.415140  [8.38208592649, 19.8712268123]\n",
       "13              -1.315686  [6.97503263407, 20.2014422706]\n",
       "14              -1.315686  [6.97503263407, 20.2014422706]\n",
       "15              -1.315686  [6.97503263407, 20.2014422706]\n",
       "16              -1.315686  [6.97503263407, 20.2014422706]\n",
       "17              -1.315686  [6.97503263407, 20.2014422706]\n",
       "18              -1.070401  [7.98173360268, 18.6401116949]\n",
       "19              -1.066450  [7.10899129469, 20.9795797765]\n",
       "20              -1.066450  [7.10899129469, 20.9795797765]\n",
       "21              -1.489592   [6.6686537179, 22.6773977697]\n",
       "22              -1.489592   [6.6686537179, 22.6773977697]\n",
       "23              -2.576313  [8.33565297296, 25.5545207379]\n",
       "24              -1.997970  [9.26245316467, 24.7619198777]\n",
       "25              -1.997970  [9.26245316467, 24.7619198777]\n",
       "26              -4.716039  [13.5564235795, 23.8209134901]\n",
       "27              -4.716039  [13.5564235795, 23.8209134901]\n",
       "28              -4.716039  [13.5564235795, 23.8209134901]\n",
       "29              -3.384662  [12.8841377151, 23.4003276803]\n",
       "...                   ...                             ...\n",
       "4970            -1.263057  [12.5713861744, 16.6249206265]\n",
       "4971            -2.695374  [11.9650971125, 14.3135458261]\n",
       "4972            -1.013874  [12.3137576346, 16.9865388333]\n",
       "4973            -1.013874  [12.3137576346, 16.9865388333]\n",
       "4974            -1.013874  [12.3137576346, 16.9865388333]\n",
       "4975            -1.013874  [12.3137576346, 16.9865388333]\n",
       "4976            -1.013874  [12.3137576346, 16.9865388333]\n",
       "4977            -1.013874  [12.3137576346, 16.9865388333]\n",
       "4978            -1.762624  [12.6664151423, 15.7106073749]\n",
       "4979            -1.762624  [12.6664151423, 15.7106073749]\n",
       "4980            -3.189668   [14.638704364, 15.4446450984]\n",
       "4981            -3.391823  [14.8454673663, 15.4395006605]\n",
       "4982            -4.333006  [14.7817210533, 13.7686983742]\n",
       "4983            -1.736785  [13.1654098508, 16.2165969536]\n",
       "4984            -1.736785  [13.1654098508, 16.2165969536]\n",
       "4985            -1.736785  [13.1654098508, 16.2165969536]\n",
       "4986            -1.736785  [13.1654098508, 16.2165969536]\n",
       "4987            -2.151977  [12.3666484503, 15.0063617551]\n",
       "4988            -1.780871  [13.6690386714, 19.1561400494]\n",
       "4989            -0.677163  [12.2034461395, 18.0600269499]\n",
       "4990            -0.966687  [9.45445477327, 17.2240279718]\n",
       "4991            -0.966687  [9.45445477327, 17.2240279718]\n",
       "4992            -0.966687  [9.45445477327, 17.2240279718]\n",
       "4993            -0.919091  [8.48391877896, 18.2445215839]\n",
       "4994            -0.919091  [8.48391877896, 18.2445215839]\n",
       "4995            -0.830983  [12.3627094618, 17.6645926402]\n",
       "4996            -0.830983  [12.3627094618, 17.6645926402]\n",
       "4997            -0.499284   [10.976276846, 17.5621315409]\n",
       "4998            -0.993457  [9.54927158214, 17.1139946106]\n",
       "4999            -1.524143  [11.4809659176, 15.7240042715]\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out = mh_sample(log_test_distribution, np.array([5, 15]), cov, args=(mu, inv_cov))\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First mean: 9.94122145874\n",
      "Second mean: 20.1504886394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.23496647, -1.87220312],\n",
       "       [-1.87220312,  6.07966491]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Variables for keeping track of totals for both means so we can get average later\n",
    "totalFirst = 0\n",
    "totalSecond = 0\n",
    "count = 0\n",
    "\n",
    "first = []\n",
    "second = []\n",
    "for i in _out['Samples']:\n",
    "    first.append(i[0])\n",
    "    second.append(i[1])\n",
    "    totalFirst += i[0]\n",
    "    totalSecond += i[1]\n",
    "    count += 1\n",
    "print (\"First mean:\", totalFirst/count)\n",
    "print (\"Second mean:\", totalSecond/count)\n",
    "np.cov(first, second)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that the means and covariance from the MCMC closely resembles their true respective values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Looks like your test worked, but is a bit off. Also, would be nice to visualize convergence with a corner plot, or a plot of one of the walker's trajectories. Any ideas for how to get a more accurate solution. (Hint: why didn't you change your kwargs for `n_steps`?) 20/20 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compute the means and covariance (using `np.cov()`) of your samples, you should come close to the inputed means and covariance. You might also want to plot your samples using `corner.corner()` to make sure everything makes sense.\n",
    "\n",
    "**c)** (20 pts extra credit) Add in some logic to your Metropolis-Hastings sampler to enable *tuning*. This is the process of automatically adjusting the $\\sigma$ in the proposal distribution such that the acceptance rate is desirable. The target acceptance rate is about 0.4. The developers of [PyMC3](https://github.com/pymc-devs/pymc3) use the scheme below, which is reasonable.\n",
    "\n",
    "|Acceptance rate|Standard deviation adaptation|\n",
    "|:---:|:-------------------:|\n",
    "| < 0.001        |$\\times$ 0.1|\n",
    "|< 0.05         |$\\times$ 0.5|\n",
    "|< 0.2          |$\\times$ 0.9|\n",
    "|> 0.5          |$\\times$ 1.1|\n",
    "|> 0.75         |$\\times$ 2|\n",
    "|> 0.95         |$\\times$ 10|\n",
    "\n",
    "Be sure to test your code to demonstrate that it works.\n",
    "\n",
    "**d)** (20 pts extra credit) Either adapt the functions you already wrote or write new ones to enable sampling of discrete variables. Again, be sure to test your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 4.1, PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated covariance matrix after adjustment to get quality acceptance rate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  8.73149835,  -4.36574918],\n",
       "       [ -4.36574918,  13.09724753]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE BELOW FOR PART C\n",
    "\n",
    "def returnAcceptanceRate(log_post, x0, sigma, args=(), n_burn=1000, n_steps=5000,\n",
    "              variable_names=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_post : function\n",
    "        The function to compute the log posterior. It has call\n",
    "        signature `log_post(x, *args)`.\n",
    "    x0 : ndarray, shape (n_variables,)\n",
    "        The starting location of a walker in parameter space.\n",
    "    sigma : ndarray, shape (n_variables, )\n",
    "        The standard deviations for the proposal distribution.\n",
    "    args : tuple\n",
    "        Additional arguments passed to `log_post()` function.\n",
    "    n_burn : int, default 1000\n",
    "        Number of burn-in steps.\n",
    "    n_steps : int, default 1000\n",
    "        Number of steps to take after burn-in.\n",
    "    variable_names : list, length n_variables\n",
    "        List of names of variables. If None, then variable names\n",
    "        are sequential integers.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output : DataFrame\n",
    "        The first `n_variables` columns contain the samples.\n",
    "        Additionally, column 'lnprob' has the log posterior value\n",
    "        at each sample.\n",
    "    \"\"\"\n",
    "    finalPoint = x0\n",
    "    new_mu, new_cov = args\n",
    "    logPostCurrent = log_post(x0, *args)\n",
    "    isAccepted = True\n",
    "    \n",
    "    #This is for fine tuning\n",
    "    totalIsAccepted = 0;\n",
    "    #Burn-in period\n",
    "    \n",
    "    for i in range(n_burn):\n",
    "        finalPoint, logPostCurrent, isAccepted = mh_step(finalPoint, log_post, logPostCurrent, sigma, args)\n",
    "    \n",
    "    #After burn-in, we actually log in sample and log posterior values\n",
    "    for j in range(n_steps):\n",
    "        finalPoint, logPostCurrent, isAccepted = mh_step(finalPoint, log_post, logPostCurrent, sigma, args)\n",
    "        if (isAccepted):\n",
    "            totalIsAccepted += 1;\n",
    "    return (totalIsAccepted/n_steps)\n",
    "\n",
    "\n",
    "# This below updates the cov/sigma until we get a good enough acceptance rate for our data\n",
    "returnAcceptanceRate1 = returnAcceptanceRate(log_test_distribution, np.array([5, 15]), cov , args=(mu, inv_cov))\n",
    "while (returnAcceptanceRate1 < 0.38 or returnAcceptanceRate1 > 0.42):\n",
    "    if returnAcceptanceRate1 < 0.001:\n",
    "        cov = cov * 0.1\n",
    "        returnAcceptanceRate1 = returnAcceptanceRate(log_test_distribution, np.array([5, 15]), cov , args=(mu, inv_cov))\n",
    "    elif returnAcceptanceRate1 < 0.05:\n",
    "        cov = cov * 0.5\n",
    "        returnAcceptanceRate1 = returnAcceptanceRate(log_test_distribution, np.array([5, 15]), cov , args=(mu, inv_cov))\n",
    "    elif returnAcceptanceRate1 < 0.38:\n",
    "        cov = cov * 0.95\n",
    "        returnAcceptanceRate1 = returnAcceptanceRate(log_test_distribution, np.array([5, 15]), cov , args=(mu, inv_cov))\n",
    "    elif returnAcceptanceRate1 > 0.95:\n",
    "        cov = cov * 10\n",
    "        returnAcceptanceRate1 = returnAcceptanceRate(log_test_distribution, np.array([5, 15]), cov , args=(mu, inv_cov))\n",
    "    elif returnAcceptanceRate1 > 0.75:\n",
    "        cov = cov * 2\n",
    "        returnAcceptanceRate1 = returnAcceptanceRate(log_test_distribution, np.array([5, 15]), cov , args=(mu, inv_cov))\n",
    "    elif returnAcceptanceRate1 > 0.42:\n",
    "        cov = cov * 1.05\n",
    "        returnAcceptanceRate1 = returnAcceptanceRate(log_test_distribution, np.array([5, 15]), cov , args=(mu, inv_cov))\n",
    "    else:\n",
    "        break;\n",
    "\n",
    "print (\"The updated covariance matrix after adjustment to get quality acceptance rate\")\n",
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Just a note about copying and pasting code: Your doc-string is wrong now!  \n",
    "\n",
    "This is an interesting approach to the tuning problem - it still helps you find an optimal $\\sigma$ for the proposal distribution, but it's computationally intensive. You can see in Justin's solution that rather than tuning $\\sigma$ only once, he checks the acceptance rate every 100 steps, and so tunes $\\sigma$ (if necessary) every 100 steps. This way, he runs the MCMC only once, but still gets a good acceptance ratio overall. Your implementation has a much stricter requirement, as it must overall have a 0.4 acceptance ratio. (Note also that the point of tuning is to use your `n_steps` more effectively. Your approach would require you to run the simulation for 3 or 4 times that number of steps!)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final acceptance rate after updating the cov is : 0.4182\n"
     ]
    }
   ],
   "source": [
    "# Now, with the updated cov, we will run to see the acceptance rate.\n",
    "returnAcceptanceRateFinal = returnAcceptanceRate(log_test_distribution, np.array([5, 15]), cov , args=(mu, inv_cov))\n",
    "print (\"The final acceptance rate after updating the cov is :\", returnAcceptanceRateFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First mean: 9.97524318229\n",
      "Second mean: 19.9745178116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.09419977, -2.00469546],\n",
       "       [-2.00469546,  6.19378674]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out = mh_sample(log_test_distribution, np.array([5, 15]), cov, args=(mu, inv_cov))\n",
    "\n",
    "#Variables for keeping track of totals for both means so we can get average later\n",
    "totalFirst = 0\n",
    "totalSecond = 0\n",
    "count = 0\n",
    "\n",
    "\n",
    "first = []\n",
    "second = []\n",
    "for i in _out['Samples']:\n",
    "    first.append(i[0])\n",
    "    second.append(i[1])\n",
    "    totalFirst += i[0]\n",
    "    totalSecond += i[1]\n",
    "    count += 1\n",
    "print (\"First mean:\", totalFirst/count)\n",
    "print (\"Second mean:\", totalSecond/count)\n",
    "np.cov(first, second)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closely following the scheme provided, we keep updating the cov matrix until we get an acceptance rate that is close to 0.4 as desired. As can be seen above, the final cov/sigma differs from the initial cov sent in, and the acceptance rate with the final cov/sigma is 0.408, awfully close to 0.4 which is good. Once again, we see that the MCMC calculated means and cov matrix resemble their true respective values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Good job testing that tuning works. You can also see that it's much more accurate than your results without tuning, using the same number of steps. 20/20 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 4.1, PART D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First mean: 10\n",
      "Second mean: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.94800544, -2.01523841],\n",
       "       [-2.01523841,  5.84869918]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE FOR PART D\n",
    "\n",
    "def mh_step_discrete(x, log_post, log_post_current, sigma, args=()):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray, shape (n_variables,)\n",
    "        The present location of the walker in parameter space.\n",
    "    log_post : function\n",
    "        The function to compute the log posterior. It has call\n",
    "        signature `log_post(x, *args)`.\n",
    "    log_post_current : float\n",
    "        The current value of the log posterior.\n",
    "    sigma : ndarray, shape (n_variables, )\n",
    "        The standard deviations for the proposal distribution.\n",
    "    args : tuple\n",
    "        Additional arguments passed to `log_post()` function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_out : ndarray, shape (n_variables,)\n",
    "        The position of the walker after the Metropolis-Hastings\n",
    "        step. If no step is taken, returns the inputted `x`.\n",
    "    log_post_updated : float\n",
    "        The log posterior after the step.\n",
    "    accepted : bool\n",
    "        True is the proposal step was taken, False otherwise.\n",
    "    \"\"\"\n",
    "    mu, inv_cov = args\n",
    "    \n",
    "    #Sample next point\n",
    "    nextPoint = np.random.multivariate_normal(x, cov)\n",
    "\n",
    "    #Calculate metropolis ratio\n",
    "    logmetropolisRatio = log_post(nextPoint, *args) - log_post_current\n",
    "    \n",
    "    #This is converting the log metropolis ratio to an actual value between 0 and 1 for probability\n",
    "    logMetropolisRatioEx = np.exp(log_post(nextPoint, *args))/ np.exp(log_post_current)\n",
    "    \n",
    "    #Random decimal between 0 and 1 to decide if we should proceed with new point at a certain probability\n",
    "    n = random.uniform(0,1)\n",
    "    \n",
    "    #Because points must have discrete values, casting is used\n",
    "    nextPoint = [int(round(nextPoint[0])), int(round(nextPoint[1]))]\n",
    "    x = [int(round(x[0])), int(round(x[1]))]\n",
    "    #If metropolis ratio is >= 1 or the random n is less than the probability (meaning we proceed with the new point)\n",
    "    #at a probability of logMetropolisRatioEx\n",
    "    if (logmetropolisRatio >= 1 or n <= logMetropolisRatioEx):\n",
    "        return nextPoint, log_post(np.array(nextPoint), *args), True\n",
    "    else:\n",
    "        return x, log_post_current, False\n",
    "    \n",
    "def mh_sample_discrete(log_post, x0, sigma, args=(), n_burn=1000, n_steps=5000,\n",
    "              variable_names=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_post : function\n",
    "        The function to compute the log posterior. It has call\n",
    "        signature `log_post(x, *args)`.\n",
    "    x0 : ndarray, shape (n_variables,)\n",
    "        The starting location of a walker in parameter space.\n",
    "    sigma : ndarray, shape (n_variables, )\n",
    "        The standard deviations for the proposal distribution.\n",
    "    args : tuple\n",
    "        Additional arguments passed to `log_post()` function.\n",
    "    n_burn : int, default 1000\n",
    "        Number of burn-in steps.\n",
    "    n_steps : int, default 1000\n",
    "        Number of steps to take after burn-in.\n",
    "    variable_names : list, length n_variables\n",
    "        List of names of variables. If None, then variable names\n",
    "        are sequential integers.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output : DataFrame\n",
    "        The first `n_variables` columns contain the samples.\n",
    "        Additionally, column 'lnprob' has the log posterior value\n",
    "        at each sample.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    lnprob = []\n",
    "    finalPoint = x0\n",
    "    new_mu, new_cov = args\n",
    "    logPostCurrent = log_post(x0, *args)\n",
    "    isAccepted = True\n",
    "    \n",
    "    #Burn-in period\n",
    "    \n",
    "    for i in range(n_burn):\n",
    "        finalPoint, logPostCurrent, isAccepted = mh_step_discrete(finalPoint, log_post, logPostCurrent, sigma, args)\n",
    "    \n",
    "    #After burn-in, we actually log in sample and log posterior values\n",
    "    for j in range(n_steps):\n",
    "        finalPoint, logPostCurrent, isAccepted = mh_step_discrete(finalPoint, log_post, logPostCurrent, sigma, args)\n",
    "        samples.append(finalPoint)\n",
    "        lnprob.append(logPostCurrent)\n",
    "    d = {'Samples': samples, 'Log Posterior Value': lnprob}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df\n",
    "\n",
    "_out = mh_sample_discrete(log_test_distribution, np.array([5, 15]), cov, args=(mu, inv_cov))\n",
    "\n",
    "#Variables for keeping track of totals for both means so we can get average later\n",
    "totalFirst = 0\n",
    "totalSecond = 0\n",
    "count = 0\n",
    "\n",
    "first = []\n",
    "second = []\n",
    "for i in _out['Samples']:\n",
    "    first.append(i[0])\n",
    "    second.append(i[1])\n",
    "    totalFirst += i[0]\n",
    "    totalSecond += i[1]\n",
    "    count += 1\n",
    "    \n",
    "# Returning means that are discrete which calls for casting\n",
    "print (\"First mean:\", int(round(totalFirst/count)))\n",
    "print (\"Second mean:\", int(round(totalSecond/count)))\n",
    "np.cov(first, second)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take into account sampling of discrete variables, we merely have to cast the returned location of walker to an integer. When first attempting this remedy, we did a mere integer cast by itself, which essentially would always round down whatever value was getting ready to returned. Due to this, we were getting mean estimates that were always below what was inputted. To better use casting, we did an integer cast AFTER rounding the value to the nearest number. This ultimately outputted the means of 10 and 20 which resembles their true values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Useful analysis. Would have been nice to see the discrete distribution! Note that you could have simplified your code by using a kwarg like `discrete` that is true or false, or passing the version of `mh_step` that shoudlld be used. Also, can you explain why it's okay to compute the Metropolis ratio the same way, even though you've changed the proposal distribution by rounding? 15/20.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Final: 95/60 </div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
